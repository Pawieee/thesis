{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26f36d3",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# BASELINE DENSENET121 PRETRAINING (GENUINE VS FORGED)\n",
    "# =============================================================================\n",
    "Pretrain DenseNet121 baseline model on 150 background users for binary classification (genuine vs forged).\n",
    "Output: baseline_pretrain.pth weights to be used in cross-validation on 110 evaluation users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2e9a0",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 1: SETUP, IMPORTS, AND REPRODUCIBILITY\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Set repo root\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "REPO_ROOT = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.append(REPO_ROOT)\n",
    "\n",
    "# Import Custom Modules\n",
    "from models.feature_extractor import DenseNetFeatureExtractor\n",
    "\n",
    "# Deterministic Seeding for Reproducible Research\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\" > [System] Seed set to: {seed}\")\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# Device Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" > [System] Computation Device: {DEVICE}\")\n",
    "print(f\" > [System] CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a617646",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 2: HYPERPARAMETER CONFIGURATION\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ecc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Input Configuration ---\n",
    "IMG_SIZE = 224\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "BATCH_SIZE = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "FINETUNE_LR = 1e-5          # Lower LR for backbone fine-tuning\n",
    "EPOCHS = 30                  # Total epochs\n",
    "FREEZE_EPOCHS = 10           # Phase 1: train head only (backbone frozen)\n",
    "                              # Phase 2: epochs FREEZE_EPOCHS+1..EPOCHS (backbone unfrozen)\n",
    "\n",
    "# --- Data Configuration ---\n",
    "# Use 150 background users\n",
    "BACKGROUND_USERS_PATH = os.path.join(REPO_ROOT, 'data', 'splits', 'bhsig_background_users.json')\n",
    "\n",
    "# --- Checkpoint Configuration ---\n",
    "CHECKPOINT_DIR = os.path.join(REPO_ROOT, 'checkpoints', 'baseline_pretraining')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"[Config] Image Size: {INPUT_SHAPE}\")\n",
    "print(f\"[Config] Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"[Config] Learning Rate (head): {LEARNING_RATE}\")\n",
    "print(f\"[Config] Learning Rate (fine-tune): {FINETUNE_LR}\")\n",
    "print(f\"[Config] Total Epochs: {EPOCHS}\")\n",
    "print(f\"[Config] Frozen Epochs (Phase 1): {FREEZE_EPOCHS}\")\n",
    "print(f\"[Config] Fine-tune Epochs (Phase 2): {EPOCHS - FREEZE_EPOCHS}\")\n",
    "print(f\"[Config] Background Users File: {BACKGROUND_USERS_PATH}\")\n",
    "print(f\"[Config] Checkpoints: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06214c",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 3: DATA CONSOLIDATION AND BACKGROUND USER SPLIT\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# 1. Fix REPO_ROOT to point to the parent 'thesis' folder, not 'notebooks'\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "if 'notebooks' in current_dir:\n",
    "    REPO_ROOT = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "else:\n",
    "    REPO_ROOT = current_dir\n",
    "\n",
    "print(f\"Project Root: {REPO_ROOT}\")\n",
    "\n",
    "# 2. Define Paths relative to the correct Root\n",
    "DATA_ROOT = os.path.join(REPO_ROOT, 'data', 'bhsig260-hindi-bengali')\n",
    "\n",
    "# Fallback: if the Kaggle folder name is different, allow direct repo/data\n",
    "if not os.path.isdir(DATA_ROOT):\n",
    "    alt_root = os.path.join(REPO_ROOT, 'data')\n",
    "    if os.path.isdir(alt_root):\n",
    "        DATA_ROOT = alt_root\n",
    "\n",
    "working_dir = os.path.join(REPO_ROOT, 'data')\n",
    "genuine_dir = os.path.join(working_dir, 'all_genuine')\n",
    "forged_dir = os.path.join(working_dir, 'all_forged')\n",
    "splits_dir = os.path.join(working_dir, 'splits')\n",
    "\n",
    "# Create clean directories\n",
    "for d in [genuine_dir, forged_dir, splits_dir]:\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"Status: Consolidating BHSig dataset (Hindi + Bengali) into a unified structure...\")\n",
    "\n",
    "# Verify source data exists\n",
    "if os.path.isdir(DATA_ROOT):\n",
    "    # Copy genuine signatures\n",
    "    hindi_gen = os.path.join(DATA_ROOT, 'BHSig160_Hindi', 'Genuine')\n",
    "    bengali_gen = os.path.join(DATA_ROOT, 'BHSig100_Bengali', 'Genuine')\n",
    "    \n",
    "    if os.path.isdir(hindi_gen):\n",
    "        os.system(f'cp -r \"{hindi_gen}/\"* \"{genuine_dir}/\" 2>/dev/null || true')\n",
    "    if os.path.isdir(bengali_gen):\n",
    "        os.system(f'cp -r \"{bengali_gen}/\"* \"{genuine_dir}/\" 2>/dev/null || true')\n",
    "    \n",
    "    # Copy forged signatures\n",
    "    hindi_forg = os.path.join(DATA_ROOT, 'BHSig160_Hindi', 'Forged')\n",
    "    bengali_forg = os.path.join(DATA_ROOT, 'BHSig100_Bengali', 'Forged')\n",
    "    \n",
    "    if os.path.isdir(hindi_forg):\n",
    "        os.system(f'cp -r \"{hindi_forg}/\"* \"{forged_dir}/\" 2>/dev/null || true')\n",
    "    if os.path.isdir(bengali_forg):\n",
    "        os.system(f'cp -r \"{bengali_forg}/\"* \"{forged_dir}/\" 2>/dev/null || true')\n",
    "    \n",
    "    print(f\" > Genuine files: {len(os.listdir(genuine_dir))}\")\n",
    "    print(f\" > Forged files: {len(os.listdir(forged_dir))}\")\n",
    "else:\n",
    "    print(f\"ERROR: Data source not found at {DATA_ROOT}\")\n",
    "\n",
    "# --- FIX START: Use Absolute Path for Script ---\n",
    "print(\" > Generating dataset splits...\")\n",
    "\n",
    "# Construct the full path to the script\n",
    "script_path = os.path.join(REPO_ROOT, 'scripts', 'restructure_bhsig.py')\n",
    "\n",
    "# Verify the script exists before running\n",
    "if not os.path.exists(script_path):\n",
    "    print(f\"CRITICAL ERROR: Script not found at: {script_path}\")\n",
    "else:\n",
    "    # Run using the absolute path\n",
    "    script_cmd = f\"python \\\"{script_path}\\\" --base_dir \\\"{DATA_ROOT}\\\" --output_dir \\\"{splits_dir}\\\" --pretrain_users 150\"\n",
    "    exit_code = os.system(script_cmd)\n",
    "    \n",
    "    if exit_code != 0:\n",
    "        print(f\"Error: Script failed with exit code {exit_code}\")\n",
    "\n",
    "# Load the identified background users\n",
    "background_users_path = os.path.join(splits_dir, 'bhsig_background_users.json')\n",
    "if os.path.exists(background_users_path):\n",
    "    with open(background_users_path, 'r') as f:\n",
    "        background_users_dict = json.load(f)\n",
    "    background_users = list(background_users_dict.keys())\n",
    "    print(f\"Success: Loaded {len(background_users)} users for the Pre-training phase.\")\n",
    "else:\n",
    "    background_users_dict = {}\n",
    "    background_users = []\n",
    "    print(\"Error: Background users file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET CLASS FOR GENUINE VS FORGED CLASSIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "class BHSigDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for Genuine vs Forged Classification (Binary Classification)\n",
    "    Label 0: Genuine signature\n",
    "    Label 1: Forged signature\n",
    "    \"\"\"\n",
    "    def __init__(self, user_dict, user_list, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_dict: Dictionary of users with genuine/forged image paths\n",
    "            user_list: List of user IDs to use\n",
    "            transform: Image transformation pipeline\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        \n",
    "        # Collect all samples with binary labels (0=genuine, 1=forged)\n",
    "        for uid in user_list:\n",
    "            if uid in user_dict:\n",
    "                user_data = user_dict[uid]\n",
    "                \n",
    "                # Add genuine samples (label = 0)\n",
    "                for img_path in user_data['genuine']:\n",
    "                    self.samples.append((img_path, 0))\n",
    "                \n",
    "                # Add forged samples (label = 1)\n",
    "                for img_path in user_data['forged']:\n",
    "                    self.samples.append((img_path, 1))\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        # Count samples per class\n",
    "        num_genuine = sum(1 for _, label in self.samples if label == 0)\n",
    "        num_forged = sum(1 for _, label in self.samples if label == 1)\n",
    "        \n",
    "        print(f\"   Dataset initialized: {len(self.samples)} total samples\")\n",
    "        print(f\"   - Genuine: {num_genuine} samples (label=0)\")\n",
    "        print(f\"   - Forged: {num_forged} samples (label=1)\")\n",
    "        print(f\"   - From {len(user_list)} users\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a blank tensor on error\n",
    "            img = torch.zeros(3, IMG_SIZE, IMG_SIZE)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# =============================================================================\n",
    "# DATA TRANSFORMATIONS\n",
    "# =============================================================================\n",
    "\n",
    "# Training transformations with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(INPUT_SHAPE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.1, 0.1),\n",
    "        scale=(0.9, 1.1),\n",
    "        fill=0\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\" > [Info] Dataset class and transformations defined for binary classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf9fe7",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 4: CREATE BINARY CLASSIFICATION DATASET (GENUINE VS FORGED)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a82304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset using the 150 background users\n",
    "user_data_dict = background_users_dict\n",
    "num_classes = 2\n",
    "\n",
    "print(\" > Creating pretraining dataset for binary classification (Genuine vs Forged)...\")\n",
    "print(f\" > Number of classes: {num_classes} (0=Genuine, 1=Forged)\")\n",
    "print(f\" > Using {len(background_users)} background users\")\n",
    "pretrain_dataset = BHSigDataset(user_data_dict, background_users, transform=train_transform)\n",
    "pretrain_loader = DataLoader(\n",
    "    pretrain_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4, \n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(\" > Pretraining dataloader ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ceb4a3",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 5: MODEL INITIALIZATION\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd224a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model for binary classification (genuine vs forged)\n",
    "model = DenseNetFeatureExtractor(\n",
    "    backbone_name='densenet121',\n",
    "    output_dim=num_classes,\n",
    "    pretrained=True,\n",
    "    baseline=True\n",
    ").to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\" > Model: DenseNet121 Baseline\")\n",
    "print(f\" > Total Parameters: {total_params:,}\")\n",
    "print(f\" > Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\" > Output Classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152a095",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 6: PRETRAINING EXECUTION\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a17131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Phase 1: Head-only training (backbone frozen) ---\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE, weight_decay=1e-4\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {'loss': [], 'accuracy': [], 'phase': []}\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 1: HEAD-ONLY TRAINING (Backbone Frozen)\")\n",
    "print(f\"  Epochs 1-{FREEZE_EPOCHS} | LR: {LEARNING_RATE}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # === Phase transition: unfreeze backbone at FREEZE_EPOCHS ===\n",
    "    if epoch == FREEZE_EPOCHS:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PHASE 2: FINE-TUNING (Backbone Unfrozen)\")\n",
    "        print(f\"  Epochs {FREEZE_EPOCHS+1}-{EPOCHS} | LR: {FINETUNE_LR}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "        # Unfreeze all backbone parameters\n",
    "        for param in model.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Re-create optimizer with all parameters and lower LR\n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': model.backbone.parameters(), 'lr': FINETUNE_LR},\n",
    "            {'params': model.custom_head.parameters(), 'lr': FINETUNE_LR}\n",
    "        ], weight_decay=1e-4)\n",
    "\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "        )\n",
    "\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"  Trainable Parameters after unfreeze: {trainable_params:,}\\n\")\n",
    "\n",
    "    current_phase = 1 if epoch < FREEZE_EPOCHS else 2\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(pretrain_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Phase {current_phase}]\", leave=False)\n",
    "\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': f\"{100*correct/total:.2f}%\"})\n",
    "\n",
    "    avg_loss = running_loss / len(pretrain_loader)\n",
    "    avg_acc = correct / total\n",
    "\n",
    "    history['loss'].append(avg_loss)\n",
    "    history['accuracy'].append(avg_acc)\n",
    "    history['phase'].append(current_phase)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d} [P{current_phase}] | Loss: {avg_loss:.4f} | Acc: {avg_acc:.2%} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        ckpt_path = os.path.join(CHECKPOINT_DIR, f\"best_pretrain_model.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'num_classes': num_classes,\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': avg_acc\n",
    "        }, ckpt_path)\n",
    "        print(f\"   >>> Best Model Saved! (Loss: {avg_loss:.4f})\")\n",
    "\n",
    "    # Save checkpoint every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_path = os.path.join(CHECKPOINT_DIR, f\"pretrain_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Pretraining Complete!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cf6d6",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 7: SAVE FINAL PRETRAINED WEIGHTS\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb992d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights_path = os.path.join(REPO_ROOT, \"baseline_pretrain.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'num_classes': num_classes,\n",
    "    'final_loss': history['loss'][-1],\n",
    "    'final_accuracy': history['accuracy'][-1],\n",
    "    'config': {\n",
    "        'img_size': INPUT_SHAPE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': EPOCHS\n",
    "    }\n",
    "}, final_weights_path)\n",
    "\n",
    "print(f\"\\n > Final pretrained weights saved to: {final_weights_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5b5cc",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# STEP 8: TRAINING VISUALIZATION\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves with phase boundary\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['loss'], color='steelblue', linewidth=2)\n",
    "axes[0].axvline(x=FREEZE_EPOCHS, color='red', linestyle='--', alpha=0.7, label='Unfreeze Backbone')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Pretraining Loss', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot([a*100 for a in history['accuracy']], color='green', linewidth=2)\n",
    "axes[1].axvline(x=FREEZE_EPOCHS, color='red', linestyle='--', alpha=0.7, label='Unfreeze Backbone')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Pretraining Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = os.path.join(CHECKPOINT_DIR, 'pretraining_curves.png')\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\" > Training curves saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c30da7",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# PRETRAINING SUMMARY\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRETRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: Baseline DenseNet121 (Genuine vs Forged Binary Classification)\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"   - Image Size: {INPUT_SHAPE}\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   - Total Epochs: {EPOCHS}\")\n",
    "print(f\"   - Phase 1 (Frozen): {FREEZE_EPOCHS} epochs @ LR={LEARNING_RATE}\")\n",
    "print(f\"   - Phase 2 (Fine-tune): {EPOCHS - FREEZE_EPOCHS} epochs @ LR={FINETUNE_LR}\")\n",
    "print(f\"   - Number of Classes: {num_classes} (0=Genuine, 1=Forged)\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"   - Training Users: {len(background_users)} (150 background users)\")\n",
    "print(f\"   - Training Samples: {len(pretrain_dataset)}\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"   - Final Loss: {history['loss'][-1]:.4f}\")\n",
    "print(f\"   - Final Accuracy: {history['accuracy'][-1]:.2%}\")\n",
    "print(f\"   - Best Loss: {best_loss:.4f}\")\n",
    "print(f\"\\nSaved Artifacts:\")\n",
    "print(f\"   - Pretrained Weights: {final_weights_path}\")\n",
    "print(f\"   - Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"   - Training Curves: {plot_path}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPretraining Complete!\")\n",
    "print(\"Next: Run baseline_kfold_validation.ipynb for cross-validation\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
